{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 6: Practical - GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "To approach the problem of image generation in a very generic way we assume that the training data comes from an unknown data generating distribution and start with two key components:\n",
    "\n",
    "- The unknown probability distribution function $p_{data}(x)$, intuitively the probability of $x$ being a \"real image\" (alternatively $p_{data}(x | c)$ probability of it being an image representing an object of a certain class).\n",
    "- A way to sample from that distribution.\n",
    "\n",
    "The first problem can be addressed using a powerful neural network to model this probability distribution. If $w$ represents the parameters of that distribution, our probability now becomes:\n",
    "\n",
    "$p_{model}(x | w)$ (or $p_{model}(x | w, c)$ for the conditional case).\n",
    "\n",
    "However, to define an appropriate loss function we need a way to judge if the generated image is good.\n",
    "\n",
    "Ideally, we would evaluate the likelihood function\n",
    "\n",
    "$-\\mathbb{E}_{x \\sim p_{data}} (p_{model}(x | w))$,\n",
    "\n",
    "where $x$ is sampled from the **real** data distribution.\n",
    "\n",
    "It is usually better to use the logarithm of the likelihood instead:\n",
    "\n",
    "$Loss = -\\mathbb{E}_{x \\sim p_{data}} (\\log(p_{model}(x | w))) =  -\\mathbb{E}_{x \\sim p_{data}} \\sum_{i=1}^N \\log( p_{model}(x_i | w )$.\n",
    "\n",
    "The problem is that we **do not know** this distribution, so cannot sample from it.\n",
    "\n",
    "Generative Adversarial Networks (GANs) approach this problem by splitting it into two parts:\n",
    "\n",
    "- A Generator (G) neural network that learns a mapping from a simple (latent) probability distribution to the data distribution $p_{data}$. It takes a random vector based on a simple probability distribution and generates an image\n",
    "- A Discriminator (D) neural network (or a critic) that evaluates samples drawn from a training set consisting of images generated by the generator as well as real images.  Hence, if the discriminator is trained to output $1$ for real images and $0$ for fake images, the logarithm of the expectation above takes the form analogous to binary cross-entropy:\n",
    "\n",
    "$Loss_{discriminator} = -\\left(\\mathbb{E}_{x \\sim p_{real}} (\\log(D(x))) + \\mathbb{E}_{x \\sim p_{latent}} \\log (1-D(G(x)))\\right)$\n",
    "\n",
    "$Loss_{generator} = - \\mathbb{E}_{x \\sim p_{latent}} \\log (D(G(x)))$\n",
    "\n",
    "\n",
    "A trained GAN \"synergizes\" the two networks so that the generator creates high probability samples as judged by the discriminator.\n",
    "\n",
    "This is the standard GAN. In this practical, we will implement an extension called Wasserstein GAN (https://arxiv.org/pdf/1701.07875).\n",
    "The idea is the same, but WGAN uses a different loss function that is more stable and leads to better convergence properties:\n",
    "\n",
    "$Loss_{discriminator} = -\\left(\\mathbb{E}_{x \\sim p_{real}} D(x) - \\mathbb{E}_{x \\sim p_{latent}} D(G(x)) \\right)$,\n",
    "\n",
    "$Loss_{generator} =  - \\mathbb{E}_{x \\sim p_{latent}} D(G(x))$,\n",
    "\n",
    "where the discriminator now outputs a value between $-\\infty$ and $\\infty$ instead of $0$ and $1$.\n",
    "\n",
    "Finally, for the training to converge with this updated loss function, an additional condition needs to be set on the Critic to satisfy the so called Lipschitz Condition:\n",
    "\n",
    "$$\n",
    "\\frac{D(x_1) - D(x_2)}{||x_1 - x_2||} \\leq 1.\n",
    "$$\n",
    "\n",
    "There are several ways to inforce it, but in this practical we will use weight clipping, which is the simplest method. It simply clips the weights of the critic to a fixed range after each update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "For this example, we will download the dataset manually instead of using one from the datasets library.\n",
    "\n",
    "Let's download the dataset.\n",
    "\n",
    "https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "\n",
    "In order to make it available to a PyTorch Dataloader, we need to create a custom dataset class that inherits from the abstract torch.utils.data.Dataset class. At least three methods are required: initializer __init__, __len__ method that returns the total number of examples in the dataset, __getitem__ which returns an example from the dataset based on its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, fname)\n",
    "            for fname in os.listdir(root_dir)\n",
    "            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, 0  # dummy label (not used in GANs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We perform the usual image transformations, but this time we also normalize the image pixels to range from -1 to 1. This is needed if we want to use a tanh activation in the final layer of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "\n",
    "# Uncomment the following lines to use the custom dataset with downloaded images\n",
    "# custom_dataset = CustomImageDataset(root_dir=\"../data/img_align_celeba\", transform=transform)\n",
    "# dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# Uncomment the following liens to use datasets.CelebA dataset instead of downloading one manually:\n",
    "dataset = datasets.CelebA(root='./data', split='train', download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's look at the first image in the first batch. We'll need to undo the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch_images, next_batch_labels = next(iter(dataloader))\n",
    "_first_img = next_batch_images[0] # retrieve the first image from the batch of 32\n",
    "_first_img = (_first_img * 0.5) + 0.5\n",
    "_first_label = next_batch_labels[0] # retrieve the first label from the batch of 32\n",
    "plt.imshow(_first_img.permute(1, 2, 0), cmap='gray') # imshow requires the image to be in height x width x channels format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0][0].shape)\n",
    "_first_img = dataset[8][0] # retrieve the first image from the batch of 32\n",
    "_first_img = (_first_img * 0.5) + 0.5\n",
    "_first_label = next_batch_labels[0] # retrieve the first label from the batch of 32\n",
    "plt.imshow(_first_img.permute(1, 2, 0), cmap='gray') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We now define the Critic and the Generator neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.act1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.act2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        #self.drop2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.act3 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        #self.drop3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.act4 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        #self.drop4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.act2(x)\n",
    "        #x = self.drop2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.act3(x)\n",
    "        #x = self.drop3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.act4(x)\n",
    "        #x = self.drop4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "_critic = Critic()\n",
    "print(_critic)\n",
    "summary(_critic, input_size=(1, 3, 64, 64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.reshape = lambda x: x.view(x.size(0), z_dim, 1, 1)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(z_dim, 512, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(512, momentum=0.9)\n",
    "        self.act1 = nn.ReLU(True) # nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(256, momentum=0.9)\n",
    "        self.act2 = nn.ReLU(True) # nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128, momentum=0.9)\n",
    "        self.act3 = nn.ReLU(True) # nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64, momentum=0.9)\n",
    "        self.act4 = nn.ReLU(True) # nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reshape(x)\n",
    "\n",
    "        x = self.deconv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.deconv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.deconv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = self.deconv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "\n",
    "        x = self.deconv5(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "_z_dim = 100\n",
    "_generator = Generator(_z_dim)\n",
    "\n",
    "# Print model summary\n",
    "summary(_generator, input_size=(1, _z_dim), device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Finally we will train a WGAN and after each epoch generate some images from random noise vectors (notice the change in the loss function from the logarithmic loss terms in the regular GAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from mofresh import refresh_matplotlib, ImageRefreshWidget\n",
    "import polars as pl\n",
    "\n",
    "widget = ImageRefreshWidget(src=\"\")\n",
    "\n",
    "@refresh_matplotlib\n",
    "def losschart(data):\n",
    "    df = pl.DataFrame(data)\n",
    "    plt.plot(df[\"epoch\"], df[\"D loss\"], label=\"Discriminator Loss\")\n",
    "    plt.plot(df[\"epoch\"], df[\"G loss\"], label=\"Generator Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "datalogs = []\n",
    "\n",
    "z_dim = 100\n",
    "lr = 5e-5\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "epochs = 20\n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "critic = Critic().to(device)\n",
    "\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=lr)\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=lr)\n",
    "\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # for batch_idx, (real, _) in enumerate(dataloader):\n",
    "    # model.train()\n",
    "    train_loader_with_progress = tqdm(\n",
    "        iterable=dataloader, ncols=120, desc=f\"Epoch {epoch+1}/{epochs}\"\n",
    "    )\n",
    "    for batch_number, (real, _) in enumerate(train_loader_with_progress):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.size(0)\n",
    "\n",
    "        ## === Train Critic === ##\n",
    "        for _ in range(n_critic):\n",
    "            noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise).detach()\n",
    "            critic_real = critic(real).mean()\n",
    "            critic_fake = critic(fake).mean()\n",
    "            loss_critic = -(critic_real - critic_fake)\n",
    "\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "            # Weight clipping\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "        ## === Train Generator === ##\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        loss_gen = -critic(fake).mean()\n",
    "\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "\n",
    "        if batch_number % 100 == 0:\n",
    "            train_loader_with_progress.set_postfix(\n",
    "                {\n",
    "                    \"Batch\": f\"{batch_number}/{len(dataloader)}\",\n",
    "                    \"D loss\": f\"{loss_critic.item():.4f}\",\n",
    "                    \"G loss\": f\"{loss_gen.item():.4f}\",\n",
    "                }\n",
    "            )\n",
    "            datalogs.append(\n",
    "                {\n",
    "                    \"epoch\": epoch + batch_number / len(dataloader),\n",
    "                    \"Batch\": batch_number/len(dataloader),\n",
    "                    \"D loss\": loss_critic.item(),\n",
    "                    \"G loss\": loss_gen.item(),\n",
    "                }\n",
    "            )\n",
    "            widget.src = losschart(datalogs) \n",
    "\n",
    "\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f\"[Epoch {epoch}/{epochs}] [Batch {batch_idx}/{len(dataloader)}] \"\n",
    "        #           f\"[D loss: {loss_critic.item():.4f}] [G loss: {loss_gen.item():.4f}]\")\n",
    "\n",
    "    # Save sample images\n",
    "    with torch.no_grad():\n",
    "        fake = gen(fixed_noise).detach().cpu()\n",
    "    grid = make_grid(fake, normalize=True)\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title(f\"Epoch {epoch}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}