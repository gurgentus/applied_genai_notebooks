{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 4: Practical 2 - Convolution Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple color flag image (France tricolor flag representation in RGB)\n",
    "france = torch.tensor([\n",
    "    [[0, 0, 0, 255, 255, 255, 255, 255, 255],  # Red channel\n",
    "     [0, 0, 0, 255, 255, 255, 255, 255, 255],\n",
    "     [0, 0, 0, 255, 255, 255, 255, 255, 255]],\n",
    "\n",
    "    [[0, 0, 0, 255, 255, 255, 0, 0, 0],  # Green channel\n",
    "     [0, 0, 0, 255, 255, 255, 0, 0, 0],\n",
    "     [0, 0, 0, 255, 255, 255, 0, 0, 0]],\n",
    "\n",
    "    [[255, 255, 255, 255, 255, 255, 0, 0, 0],  # Blue channel\n",
    "     [255, 255, 255, 255, 255, 255, 0, 0, 0],\n",
    "     [255, 255, 255, 255, 255, 255, 0, 0, 0]]\n",
    "], dtype=torch.float32) # Shape: [C, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "france.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Note that we defined the 3 channels (Red, Green, Blue) in the first dimension. In order to visualize the image using matplotlib's imshow function we need to reshape the tensor to have the channel as the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "france.permute(1, 2, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "In addition, visualization libraries like matplotlib expect the pixel values to be in the range [0, 255] and of type uint8. We can convert the tensor to a numpy array and cast it to uint8 using the numpy method astype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gridlines that align with the image cells\n",
    "def visualize(image):\n",
    "    print(image.shape)\n",
    "    h, w = image.shape[:2]\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(-0.5, w, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, h, 1), minor=True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(visible=True, which='minor', color='green', linewidth=0.5)\n",
    "    ax.tick_params(which='minor', size=0)\n",
    "    if (len(image.shape) == 2):\n",
    "        plt.imshow(image, cmap = 'gray')\n",
    "        for (i, j), val in np.ndenumerate(image):\n",
    "            plt.text(j, i, f\"{val:.0f}\", ha='center', va='center', color='white' if val < 128 else 'black')\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "For this activity we will deal with a grayscale version of the France flag image. We can convert the image to grayscale by averaging the pixel values across the three channels. We can then visualize the grayscale image using the visualize function. Here we also use the squeeze method to remove the singleton dimension (C) from the tensor, since there is only one channel now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "france_grayscale = 0.2989 * france[0] + 0.5870 * france[1] + 0.1140 * france[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(france_grayscale.squeeze().numpy().astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Next, let's create a filter to detect the vertical and horizontal edges in the image. Think about what happens as we slide it across the image while performing the convolution operation (taking linear combination of image values with the coefficients specified by the filter).  Note also the unsqueeze function which increases the tensor dimension. We need this since the conv2d function from torch is designed to work with 4D tensors (B x C x H x W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vertical and horizontal filters\n",
    "vertical_filter = torch.tensor([\n",
    "    [-1, 1],\n",
    "    [-1, 1]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 2, 2]\n",
    "\n",
    "horizontal_filter = torch.tensor([\n",
    "    [-1, -1],\n",
    "    [ 1,  1]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 2, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Now let's calculate the convolution to detect any vertical changes in intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vertical_filter = torch.tensor([[-1, 1], [-1, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "horizontal_filter = torch.tensor([[-1, -1], [1, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply the vertical and horizontal filters\n",
    "vertical_edges = F.conv2d(france_grayscale.unsqueeze(0), vertical_filter)\n",
    "visualize(vertical_edges.squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's see what a flattened version of this tensor would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vertical_edges.flatten().unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activations(flag, activation, activation_label):\n",
    "    # Visualize the original flag and edge-detected images with colored edges\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Original Flag\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(flag.squeeze().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "    plt.grid(visible=True, color='black', linewidth=0.5)\n",
    "    plt.title(\"Original Flag\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Vertical Edges\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(activation.squeeze().numpy(), cmap='Reds')\n",
    "    plt.title(activation_label)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def process_flag_with_detector(flag, filter, detector, activation_label):\n",
    "    edges = F.conv2d(flag.unsqueeze(0), filter)\n",
    "    visualize_activations(flag, F.relu(edges * detector.reshape(2,8)), activation_label)\n",
    "    flattened_edges = edges.flatten().unsqueeze(1)\n",
    "    signal = F.relu(detector @ flattened_edges)\n",
    "    return signal.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Finally we can multiply each of the flattened outputs from the previous step with a vector that has positive values in positions where we want to detect positive outputs (or negative values in positions where we want to detect negative outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_flag_with_detector(france_grayscale, \n",
    "                           torch.tensor([\n",
    "        [-1, 1],\n",
    "        [-1, 1]\n",
    "    ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 2, 2]\n",
    "    ,\n",
    "                         torch.tensor(\n",
    "                     [[0, 10, 10, 0, 0, 10, 10, 0,\n",
    "                       0, 10, 10, 0, 0, 10, 10, 0]], dtype=torch.float32), activation_label = \"Increasing Intensity Vertical Edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_flag_with_detector(france_grayscale, \n",
    "                           torch.tensor([\n",
    "        [1, 1],\n",
    "        [-1, -1]\n",
    "    ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 2, 2]\n",
    "    ,\n",
    "                         torch.tensor(\n",
    "                     [[0, 10, 10, 0, 0, 10, 10, 0,\n",
    "                       0, 10, 10, 0, 0, 10, 10, 0]], dtype=torch.float32), activation_label = \"Increasing Intensity Horizontal Edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_flag_with_detector(france_grayscale, \n",
    "                           torch.tensor([\n",
    "        [-1, 1],\n",
    "        [-1, 1]\n",
    "    ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 2, 2]\n",
    "    ,\n",
    "                         torch.tensor(\n",
    "                     [[0, -10, -10, 0, 0, -10, -10, 0,\n",
    "                       0, -10, -10, 0, 0, -10, -10, 0]], dtype=torch.float32), activation_label = \"Decreasing Intensity Vertical Edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "For this example we did some feature engineering by hardcoding the values into the filter, so it picks up the specific edges we were interested in. Convolutional Neural Networks use generic weights to represent the filters, thus \"building\" the features automatically based on minimizing the loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
