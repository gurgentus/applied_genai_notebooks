{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\u26a0\ufe0f **Static Version Notice**\n",
    "\n",
    "This is a static export of an interactive marimo notebook. Some features have been modified for compatibility:\n",
    "\n",
    "- Interactive UI elements (sliders, dropdowns, text inputs) have been removed\n",
    "- UI variable references have been replaced with default values\n",
    "- Some cells may have been simplified or removed entirely\n",
    "\n",
    "For the full interactive experience, please run the original marimo notebook (.py file) using:\n",
    "```bash\n",
    "uv run marimo edit notebook_name.py\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 8: Practical 2 - Diffusion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Recall that the idea behind Diffusion Models is to map training data to a simple normal distribution by adding noise through a series of steps and then have a neural network **learn** the inverse process.\n",
    "\n",
    "In contrast to autoencoders, the first step is done through simple well defined functions and only the decoder is learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_label = train_dataset[0]\n",
    "print(first_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, label=None):\n",
    "    print(\"Label: \", label)\n",
    "    plt.figure(figsize=(4, 3)) \n",
    "    plt.imshow(image.permute(1,2,0).squeeze(), cmap='gray')\n",
    "    plt.show()\n",
    "show_image(first_image, first_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's take $x_0$ to be a random variable representing images in our data distribution. We will assume that it has mean $0$ and variance $1$. This is ok since we have preprocessed the training images to have mean $0$ and variance $1$.\n",
    "\n",
    "Next, we will corrupt the images by adding standard gaussian noise $\\epsilon$ (mean 0, variance 1). How much noise should be added?\n",
    "\n",
    "To keep the transformed distribution having the same mean and variance, we can control the noise amount using a parameter $\\beta$:\n",
    "\n",
    "$x_1 = \\sqrt{1-\\beta}x_0 + \\sqrt{\\beta} \\epsilon$\n",
    "\n",
    "Then if $x_0$ has mean $0$ and variance $1$, $x_1$ will have mean:\n",
    "\n",
    "$\\sqrt{1-\\beta}*0+\\sqrt{\\beta}*0=0$\n",
    "\n",
    "and variance:\n",
    "\n",
    "$(\\sqrt{1-\\beta})^2*1 + (\\sqrt{\\beta})^2*1=1-\\beta+\\beta=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_image(image, beta = 0.1):\n",
    "    image_with_noise = np.sqrt(1-beta)*image + np.sqrt(beta)*np.random.normal(0, 1, image.shape)\n",
    "    return image_with_noise\n",
    "# show_image(corrupt_image(first_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "How does changing $\\beta$ influence the amount of noise added to the image?  Try to find a value that makes the image look like a random noise image.  You can use the slider below to change the value of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(corrupt_image(first_image, beta=slider.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We can repeat this process using the new $x_1$ as the input to the next step, and so on, until we reach $x_T$. Moreover, we can also use a different $\\beta$ for each step. The setup of how this parameter should vary is referred to as the **diffusion schedule**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We'll want to repeat this process through several iterations, at each step corrupting the image by a small amount. To make things simpler, we can perform some mathematical magic using the fact that multiplying a Gaussian distribution by a constant results in another Gaussian distribution. Similarly, adding two Gaussians results in a Gaussian.  So, one can show mathematically that for two standard Gaussian random variables:\n",
    "\n",
    "$A \\epsilon_0 + B \\epsilon_1 = \\left(\\sqrt{A^2 + B^2}\\right)\\epsilon$, where $\\epsilon$ is also a Gaussian random variable.\n",
    "\n",
    "Hence,\n",
    "\n",
    "$x_2 = \\sqrt{1-\\beta_1}x_1 + \\sqrt{\\beta_1} \\epsilon_1 = \\sqrt{1-\\beta_1}(\\sqrt{1-\\beta_0}x_0 + \\sqrt{\\beta_0} \\epsilon_0) + \\sqrt{\\beta_1} \\epsilon_1 = \\sqrt{(1-\\beta_0)(1-\\beta_1)}x_0 + \\sqrt{\\beta_0(1-\\beta_1)}\\epsilon_0 + \\sqrt{\\beta_1}\\epsilon_1 = \\sqrt{(1-\\beta_0)(1-\\beta_1)}x_0 + \\sqrt{1 - (1-\\beta_0)(1-\\beta_1)}\\epsilon$,\n",
    "\n",
    "and so on. This will be used in defining the multipliers for the image (signal rates) and the noise (noise rates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's look at examples of several diffusion schedules:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The idea is to train a neural network to model the noise that was added. The input to this network will be the noisy image and the variance of the noise that was added (this comes from the diffusion schedule we select). The noise variance is typically encoded using some sort of an embedding, in this case a Sinusoidal Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, num_frequencies=16):\n",
    "        super().__init__()\n",
    "        self.num_frequencies = num_frequencies\n",
    "        frequencies = torch.exp(torch.linspace(math.log(1.0), math.log(1000.0), num_frequencies))\n",
    "        self.register_buffer(\"angular_speeds\", 2.0 * math.pi * frequencies.view(1, 1, 1, -1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, 1, 1, 1)\n",
    "        returns: Tensor of shape (B, 1, 1, 2 * num_frequencies)\n",
    "        \"\"\"\n",
    "        x = x.expand(-1, 1, 1, self.num_frequencies)\n",
    "        sin_part = torch.sin(self.angular_speeds * x)\n",
    "        cos_part = torch.cos(self.angular_speeds * x)\n",
    "        return torch.cat([sin_part, cos_part], dim=-1)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_diffusion_schedule(diffusion_times, min_rate=1e-4, max_rate=0.02):\n",
    "    \"\"\"\n",
    "    diffusion_times: Tensor of shape (T,) with values in [0, 1)\n",
    "    Returns:\n",
    "        noise_rates: Tensor of shape (T,)\n",
    "        signal_rates: Tensor of shape (T,)\n",
    "    \"\"\"\n",
    "    diffusion_times = diffusion_times.to(dtype=torch.float32)\n",
    "    betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    signal_rates = torch.sqrt(alpha_bars)\n",
    "    noise_rates = torch.sqrt(1.0 - alpha_bars)\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "\n",
    "def cosine_diffusion_schedule(diffusion_times):\n",
    "    # diffusion_times: Tensor of shape [T] or [B] with values in [0, 1]\n",
    "    signal_rates = torch.cos(diffusion_times * math.pi / 2)\n",
    "    noise_rates = torch.sin(diffusion_times * math.pi / 2)\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "def offset_cosine_diffusion_schedule(diffusion_times, min_signal_rate=0.02, max_signal_rate=0.95):\n",
    "    # Flatten diffusion_times to handle any shape\n",
    "    original_shape = diffusion_times.shape\n",
    "    diffusion_times_flat = diffusion_times.flatten()\n",
    "\n",
    "    # Compute start and end angles from signal rate bounds\n",
    "    start_angle = torch.acos(torch.tensor(max_signal_rate, dtype=torch.float32, device=diffusion_times.device))\n",
    "    end_angle = torch.acos(torch.tensor(min_signal_rate, dtype=torch.float32, device=diffusion_times.device))\n",
    "\n",
    "    # Linearly interpolate angles\n",
    "    diffusion_angles = start_angle + diffusion_times_flat * (end_angle - start_angle)\n",
    "\n",
    "    # Compute signal and noise rates\n",
    "    signal_rates = torch.cos(diffusion_angles).reshape(original_shape)\n",
    "    noise_rates = torch.sin(diffusion_angles).reshape(original_shape)\n",
    "\n",
    "    return noise_rates, signal_rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(train_loader))\n",
    "noises = torch.randn(size=(BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "diffusion_times = torch.rand((BATCH_SIZE,), device=images.device)  # scalar per sample\n",
    "diffusion_times = diffusion_times.view(BATCH_SIZE, 1, 1, 1)         # for broadcasting\n",
    "\n",
    "noise_rates, signal_rates = linear_diffusion_schedule(diffusion_times)\n",
    "noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "grid = make_grid(noisy_images, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Next we build the three new layers used in a UNet neural network, a popular architecture used in Diffusion Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.needs_projection = in_channels != out_channels\n",
    "        if self.needs_projection:\n",
    "            self.proj = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.proj = nn.Identity()\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(in_channels, affine=False)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def swish(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.proj(x)\n",
    "        # x = self.norm(x)\n",
    "        x = self.swish(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, width, block_depth, in_channels):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(block_depth):\n",
    "            self.blocks.append(ResidualBlock(in_channels, width))\n",
    "            in_channels = width\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            skips.append(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, width, block_depth, in_channels):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(block_depth):\n",
    "            self.blocks.append(ResidualBlock(in_channels + width, width))\n",
    "            in_channels = width\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        for block in self.blocks:\n",
    "            skip = skips.pop()\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, image_size, num_channels, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Conv2d(num_channels, 32, kernel_size=1)\n",
    "        self.num_channels = num_channels\n",
    "        self.image_size = image_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = SinusoidalEmbedding(num_frequencies=16)\n",
    "        self.embedding_proj = nn.Conv2d(embedding_dim, 32, kernel_size=1)\n",
    "\n",
    "        self.down1 = DownBlock(32, in_channels=64, block_depth=2)\n",
    "        self.down2 = DownBlock(64, in_channels=32, block_depth=2)\n",
    "        self.down3 = DownBlock(96, in_channels=64, block_depth=2) \n",
    "\n",
    "        self.mid1 = ResidualBlock(in_channels=96, out_channels=128)\n",
    "        self.mid2 = ResidualBlock(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.up1 = UpBlock(96, in_channels=128, block_depth=2) \n",
    "        self.up2 = UpBlock(64, block_depth=2, in_channels=96)\n",
    "        self.up3 = UpBlock(32, block_depth=2, in_channels=64)\n",
    "\n",
    "        self.final = nn.Conv2d(32, num_channels, kernel_size=1)\n",
    "        nn.init.zeros_(self.final.weight)  # Keep zero init like TF reference\n",
    "\n",
    "    def forward(self, noisy_images, noise_variances):\n",
    "        skips = []\n",
    "        x = self.initial(noisy_images)\n",
    "        noise_emb = self.embedding(noise_variances)  # shape: (B, 1, 1, 32)\n",
    "        # Upsample to match image size like TF reference\n",
    "        noise_emb = F.interpolate(noise_emb.permute(0, 3, 1, 2), size=(self.image_size, self.image_size), mode='nearest')\n",
    "        x = torch.cat([x, noise_emb], dim=1)\n",
    "\n",
    "        x = self.down1(x, skips)\n",
    "        x = self.down2(x, skips) \n",
    "        x = self.down3(x, skips)    \n",
    "\n",
    "        x = self.mid1(x)     \n",
    "        x = self.mid2(x)   \n",
    "\n",
    "        x = self.up1(x, skips)\n",
    "        x = self.up2(x, skips)\n",
    "        x = self.up3(x, skips)\n",
    "\n",
    "        return self.final(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, model, schedule_fn):\n",
    "        super().__init__()\n",
    "        self.network = model\n",
    "        self.ema_network = copy.deepcopy(model)\n",
    "        self.ema_network.eval()\n",
    "        self.ema_decay = 0.8\n",
    "        self.schedule_fn = schedule_fn\n",
    "        self.normalizer_mean = 0.0\n",
    "        self.normalizer_std = 1.0\n",
    "\n",
    "    def to(self, device):\n",
    "        # Override to() to ensure both networks move to the same device\n",
    "        super().to(device)\n",
    "        self.ema_network.to(device)\n",
    "        return self\n",
    "\n",
    "    def set_normalizer(self, mean, std):\n",
    "        self.normalizer_mean = mean\n",
    "        self.normalizer_std = std\n",
    "\n",
    "    def denormalize(self, x):\n",
    "        return torch.clamp(x * self.normalizer_std + self.normalizer_mean, 0.0, 1.0)\n",
    "\n",
    "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
    "        # Use EMA network for inference, main network for training\n",
    "        if training:\n",
    "            network = self.network\n",
    "            network.train()\n",
    "        else:\n",
    "            network = self.ema_network\n",
    "            network.eval()\n",
    "\n",
    "        pred_noises = network(noisy_images, noise_rates ** 2)\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "        return pred_noises, pred_images\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "        current_images = initial_noise\n",
    "        for step in range(diffusion_steps):\n",
    "            t = torch.ones((initial_noise.shape[0], 1, 1, 1), device=initial_noise.device) * (1 - step * step_size)\n",
    "            noise_rates, signal_rates = self.schedule_fn(t)\n",
    "            pred_noises, pred_images = self.denoise(current_images, noise_rates, signal_rates, training=False)\n",
    "\n",
    "            # Debug generation process\n",
    "            if step % max(1, diffusion_steps // 4) == 0:  # Print 4 times during generation\n",
    "                print(f\"Generation Step {step}/{diffusion_steps}: t={1-step*step_size:.3f}\")\n",
    "                print(f\"  Current images std: {current_images.std().item():.4f}\")\n",
    "                print(f\"  Pred images std: {pred_images.std().item():.4f}\")\n",
    "                print(f\"  Signal rate: {signal_rates.mean().item():.4f}, Noise rate: {noise_rates.mean().item():.4f}\")\n",
    "\n",
    "            next_diffusion_times = t - step_size\n",
    "            next_noise_rates, next_signal_rates = self.schedule_fn(next_diffusion_times)\n",
    "            current_images = next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
    "        return pred_images\n",
    "\n",
    "    def generate(self, num_images, diffusion_steps, image_size=64, initial_noise=None):\n",
    "        if initial_noise is None:\n",
    "            initial_noise = torch.randn((num_images, self.network.num_channels, image_size, image_size), device=next(self.parameters()).device)\n",
    "        with torch.no_grad():\n",
    "            return self.denormalize(self.reverse_diffusion(initial_noise, diffusion_steps))\n",
    "\n",
    "    def train_step(self, images, optimizer, loss_fn):\n",
    "        images = (images - self.normalizer_mean) / self.normalizer_std\n",
    "        noises = torch.randn_like(images)\n",
    "\n",
    "        diffusion_times = torch.rand((images.size(0), 1, 1, 1), device=images.device)\n",
    "        noise_rates, signal_rates = self.schedule_fn(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        pred_noises, _ = self.denoise(noisy_images, noise_rates, signal_rates, training=True)\n",
    "        loss = loss_fn(pred_noises, noises)\n",
    "\n",
    "        # Debug prints\n",
    "        if torch.rand(1).item() < 0.01:  # Print more frequently to see output\n",
    "            print(f\"Debug - Loss: {loss.item():.4f}, Noise std: {noises.std().item():.4f}, Pred std: {pred_noises.std().item():.4f}\")\n",
    "            print(f\"Signal rates range: {signal_rates.min().item():.4f}-{signal_rates.max().item():.4f}\")\n",
    "            print(f\"Noise rates range: {noise_rates.min().item():.4f}-{noise_rates.max().item():.4f}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Check for gradient issues\n",
    "        if torch.rand(1).item() < 0.01:\n",
    "            total_norm = 0\n",
    "            for p in self.network.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1. / 2)\n",
    "            print(f\"Gradient norm: {total_norm:.4f}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Debug EMA update occasionally\n",
    "            if torch.rand(1).item() < 0.001:\n",
    "                param_diff = 0\n",
    "                for ema_param, param in zip(self.ema_network.parameters(), self.network.parameters()):\n",
    "                    param_diff += (ema_param - param).abs().mean().item()\n",
    "                print(f\"EMA Update Debug - Avg param difference: {param_diff:.6f}\")\n",
    "\n",
    "            for ema_param, param in zip(self.ema_network.parameters(), self.network.parameters()):\n",
    "                ema_param.copy_(self.ema_decay * ema_param + (1. - self.ema_decay) * param)\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def test_step(self, images, loss_fn):\n",
    "        images = (images - self.normalizer_mean) / self.normalizer_std\n",
    "        noises = torch.randn_like(images)\n",
    "\n",
    "        diffusion_times = torch.rand((images.size(0), 1, 1, 1), device=images.device)\n",
    "        noise_rates, signal_rates = self.schedule_fn(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_noises, _ = self.denoise(noisy_images, noise_rates, signal_rates, training=False)\n",
    "            loss = loss_fn(pred_noises, noises)\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def plot_images(self, epoch=None, logs=None, num_rows=3, num_cols=6):\n",
    "        # plot random generated images for visual evaluation of generation quality\n",
    "        generated_images = self.generate(\n",
    "            num_images=num_rows * num_cols,\n",
    "            image_size=IMAGE_SIZE,\n",
    "            diffusion_steps=20,\n",
    "        ).cpu()\n",
    "        show_image(generated_images[0])      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The training loop looks similar to the one used in the previous modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def train_diffusion(model, train_loader, val_loader, optimizer, loss_fn, epochs=50, device='cuda', checkpoint_dir='checkpoints'):\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        loader_with_progress = tqdm(train_loader, ncols=120, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for images, _  in loader_with_progress:\n",
    "            images = images.to(device)\n",
    "            loss = model.train_step(images, optimizer, loss_fn)\n",
    "            train_losses.append(loss)\n",
    "            loader_with_progress.set_postfix(loss=f'{loss:.4f}')\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "        model.eval()\n",
    "        model.plot_images()\n",
    "\n",
    "        val_losses = []\n",
    "        for images, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            images = images.to(device)\n",
    "            loss = model.test_step(images, loss_fn)\n",
    "            val_losses.append(loss)\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        loader_with_progress.set_postfix(loss=f'{avg_train_loss:.4f}')\n",
    "\n",
    "        # Save checkpoint every epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.network.state_dict(),\n",
    "            'ema_model_state_dict': model.ema_network.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'normalizer_mean': model.normalizer_mean,\n",
    "            'normalizer_std': model.normalizer_std\n",
    "        }\n",
    "\n",
    "        # Save latest checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'diffusion_epoch_{epoch+1:03d}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_checkpoint_path = os.path.join(checkpoint_dir, 'diffusion_best.pth')\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            print(f\"New best model saved at epoch {epoch+1} with val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load a saved checkpoint and restore model, EMA, and optimizer states\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    model.network.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.ema_network.load_state_dict(checkpoint['ema_model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Restore normalizer settings\n",
    "    model.normalizer_mean = checkpoint['normalizer_mean']\n",
    "    model.normalizer_std = checkpoint['normalizer_std']\n",
    "\n",
    "    print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"Train Loss: {checkpoint['train_loss']:.4f}, Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "    return checkpoint['epoch']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCOB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images\n",
    "diffusion_model.eval()\n",
    "samples = diffusion_model.generate(num_images=1, image_size=IMAGE_SIZE, diffusion_steps=1000)  # returns tensor in [0, 1]\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "image = samples[0].cpu()\n",
    "\n",
    "# Plot\n",
    "show_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test EMA after training\n",
    "test_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "test_noise_var = torch.tensor([[[[0.5]]]]).to(device)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}