{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 8: Practical 1 - Energy Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Theoretical Part\n",
    "\n",
    "First, some math... The derivations below are somewhat complex, so do not worry if you don't follow everything. Luckily, the final loss function is simple and intuitive. The derivation is not necessary to understand the code, but gives a very nice interpretation of the final loss function.\n",
    "\n",
    "This follows a nice derivation of Contrastive Divergence found in https://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf. If you reference the above, keep in mind a change of notation: our $E$ is the same as $-log(f)$ in the derivation (equivalently $f = e^{-E}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We will derive the loss function for our energy based models using maximum likelihood. Later we will see that the resulting loss function makes sense even if we don't transform the energy into a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Start with an energy defined for all inputs $x$ and dependent on parameters $w$: $E(x, w)$. We use regular letters $x$ and $w$, but keep in mind that they represent vectors (many parameters and many input variables for each input). In addition, for many derivations and analytical results it is convenient to think of $x$ as being a continuous scalar variable instead of a high-dimensional vector. It should be clear from the context, i.e. if we integrate over $x$ it is a continuous variable, if we sum over values $x_i$ of $x$, it is a discrete vector.\n",
    "\n",
    "Note: in the practical part below, $x$ will be a tensor of image pixels and $w$ the weights in the neural network, in other words the neural network calculates the energy and we will see that we want to train it (tune the parameters $w$), so that it gives low energy to realistic images and high energy to fake images.\n",
    "\n",
    "We can transform $E$ into a probability by normalizing it as follows:\n",
    "\n",
    "$p(x,w) = \\dfrac{1}{Z(w)} e^{-E(x,w)}$,\n",
    "\n",
    "where\n",
    "\n",
    "$Z(w) = \\int e^{-E(x,w)}$.\n",
    "\n",
    "Here we are assuming that $x$ is a continuous variable, so the integration is analogous to summation in the case of $x$ being discrete valued. If you are not familiar with integration, just think about it being aproximated by \"summing\" the energy values over the possible values of $x$ (all possible images in our example). This should actually look familiar.  Remember the softmax activation?  In the discrete case, this is how we usually turn multiple outputs into a probability distribution used for classification in a neural network.\n",
    "\n",
    "The difference is that we are only using this form now to derive an appropriate loss function - with  energy models, our loss function will work directly with unnormalized energy values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Now that we have a probability function, we can use the usual Maximum Likelihood Estimation.\n",
    "\n",
    "$loss = -\\mathbb{E}_{x \\sim data} \\log p(x,w) = -\\dfrac{1}{N} \\sum \\log p(x_i, w) = -\\dfrac{1}{N} \\sum \\log \\left( \\dfrac{1}{Z(w)} e^{-E(x_i,w)} \\right) = \\dfrac{1}{N} \\sum \\left( \\log Z(w) -E(x_i, w) \\right)$.\n",
    "\n",
    "Since $Z$ doesn't depend on $i$ or $x$ this simplifies to\n",
    "\n",
    "$loss = \\log Z(w) + \\dfrac{1}{N} \\sum E(x_i, w)$.\n",
    "\n",
    "To train a neural network using gradient descent requires calculating the gradient of the loss with respect to the parameters $w$:\n",
    "\n",
    "$\\nabla_w loss = \\nabla_w \\log Z(w) + \\dfrac{1}{N} \\sum \\nabla_w E(x_i, w) =  \\nabla_w \\log Z(w)  + \\mathbb{E}_{x \\sim data} \\nabla_w E(x, w)$.\n",
    "\n",
    "We will obtain a form for the first term in terms of an expectation as well.\n",
    "\n",
    "$\\nabla_w \\log Z(w) = \\dfrac{1}{Z(w)} \\nabla_w Z(w) = \\dfrac{1}{Z(w)} \\nabla_w \\int e^{-E(x,w)} dx =  -\\dfrac{1}{Z(w)} \\int e^{- E(x,w)}  \\nabla_w E(x,w) dx = -\\dfrac{1}{Z(w)} \\int e^{- E(x,w)} \\nabla_w E(x,w) dx = -\\int p(x,w) \\nabla_w E(x,w) dx = - \\mathbb{E}_{x \\sim model} \\nabla_w E(x,w)$\n",
    "\n",
    "and the full gradient becomes\n",
    "\n",
    "$\\nabla_w loss = \\mathbb{E}_{x \\sim data} \\nabla_w E(x, w) - \\mathbb{E}_{x \\sim model} \\nabla_w E(x,w)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "In other words, minimizing this loss is equivalent to finding parameters $w$ that decrease the energy on the data and increase the energy on the model.  This is a form of contrastive divergence, where we are trying to minimize the difference between the data and the model distributions. It penalizes $x$ values \"away\" from the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Practical Part\n",
    "\n",
    "Now let's use the loss function we derived to implement an Energy Based model to generate synthetic images similar to the hand-written digits in the MNIST dataset. First the usual data preparation steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which GPU is available\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.manual_seed(42) \n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "# DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=batch_size,\n",
    "#     num_workers=num_workers,\n",
    "#     worker_init_fn=seed_worker,\n",
    "#     generator=g,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "transform = transforms.Compose([transforms.Pad(2, -1), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load/download the datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "_random_index = np.random.randint(len(train_dataset))\n",
    "_img, _label = train_dataset[_random_index]\n",
    "plt.imshow(_img.permute(1,2,0).squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We now construct the neural network that approximates the energy $E(x,w)$. The architecture is a familiar convolutional neural network, with a small addition of using the `swish` activation function instead of ReLU that we've been using before. The convolutional layers reduce the image from 32 by 32 to 2 by 2 and increase the number of channels from 1 to 64. The final fully connected layers reduce the output to a single scalar value representing the energy of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swish activation function\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnergyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = swish(self.conv1(x))\n",
    "        x = swish(self.conv2(x))\n",
    "        x = swish(self.conv3(x))\n",
    "        x = swish(self.conv4(x))\n",
    "        x = self.flatten(x)\n",
    "        x = swish(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We next create a function that samples the low energy states. We assume that we have a neural network represented by `nn_model` that maps input images to energy (often you will see the neural network designed to model negative energy $-E$ instead of $E$ as a convention, in which case you should be careful with either switching the sign before doing gradient descent or doing gradient ascent instead by adding a multiple of the gradient instead of subtracting it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(nn_energy_model, inp_imgs, steps, step_size, noise_std):\n",
    "    nn_energy_model.eval()\n",
    "\n",
    "    # As we do various calculations on the input images (like adding noise)\n",
    "    # these are added to the computational graph, however we really only\n",
    "    # need this for computing gradients during backpropogation.\n",
    "\n",
    "    # Energy: (x, w) => E(x, w)\n",
    "    # For sampling we fix the weights, and perform gradient descent with derivatives with respect to x\n",
    "    # for w in nn_energy_model.parameters():\n",
    "    #     w.requires_grad = False\n",
    "    # inp_imgs = inp_imgs.detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # We add noise to the input images, but we will\n",
    "        # need to calculate the gradients with the transformed\n",
    "        # noisy images, so tell pytorch not to track the gradient \n",
    "        # yet, this way we can avoid unnecessary computations that\n",
    "        # pytorch does in order to calculate the gradients later:\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn_like(inp_imgs) * noise_std\n",
    "            inp_imgs = (inp_imgs + noise).clamp(-1.0, 1.0)\n",
    "\n",
    "        inp_imgs.requires_grad_(True)\n",
    "\n",
    "        # Compute energy and gradients\n",
    "        energy = nn_energy_model(inp_imgs)\n",
    "\n",
    "        # The gradient with respect to parameters is usually done automatically \n",
    "        # when we train a neural network as part of .backward() call.\n",
    "        # Here we do it manually and specify that the gradient should be with \n",
    "        # respect to the input images, not the parameters.\n",
    "        # In addition because energy contains energy values for each input image\n",
    "        # in a batch, we need to specify an extra grad_outputs argument for the \n",
    "        # right gradients to be calculated for each input image.\n",
    "        grads, = torch.autograd.grad(energy, inp_imgs, grad_outputs=torch.ones_like(energy))\n",
    "\n",
    "        # Finally, apply gradient clipping for stabilizing the sampling\n",
    "        with torch.no_grad():\n",
    "            grads = grads.clamp(-0.03, 0.03)\n",
    "            inp_imgs = (inp_imgs - step_size*grads).clamp(-1.0, 1.0)\n",
    "\n",
    "    return inp_imgs.detach()\n",
    "\n",
    "# We can also use .backward() call to calculate the gradient instead of autograd.grad\n",
    "# The difference is that pytorch will automatically populate the gradients into\n",
    "# .grad attribute of the input tensor instead of returning it.\n",
    "# Compare the code below to the one above.\n",
    "\n",
    "# def generate_samples(nn_energy_model, inp_imgs, steps, step_size, noise_std):\n",
    "#     nn_energy_model.eval()\n",
    "\n",
    "#     # Energy: (x, w) => E(x, w)\n",
    "#     for w in nn_energy_model.parameters():\n",
    "#         w.requires_grad = False\n",
    "#     inp_imgs = inp_imgs.detach().requires_grad_(True)\n",
    "\n",
    "#     for _ in range(steps):\n",
    "#         with torch.no_grad():\n",
    "#             noise = torch.randn_like(inp_imgs) * noise_std\n",
    "#             inp_imgs = (inp_imgs + noise).clamp(-1.0, 1.0)\n",
    "\n",
    "#         inp_imgs.requires_grad_(True)\n",
    "\n",
    "#         # Compute energy and gradients\n",
    "#         energy = nn_energy_model(inp_imgs)\n",
    "#         energy.backward(torch.ones_like(energy))\n",
    "\n",
    "#         with torch.no_grad():     \n",
    "#             grads = inp_imgs.grad.clamp(-0.03, 0.03)\n",
    "#             inp_imgs = (inp_imgs - step_size*grads).clamp(-1.0, 1.0)\n",
    "\n",
    "#     for w in nn_energy_model.parameters():\n",
    "#         w.requires_grad = True\n",
    "\n",
    "#     return inp_imgs.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The `generate_samples` function above uses a process called *Langevin Dynamics* to generate points based on the energy defined by our neural network model. It turned out that this works only after an initial amount of gradient steps referred to as mixing time. This makes generating samples from scratch every time inefficient. One way to address this is to keep a buffer of samples and sample from it instead of starting from random noise every time. This is implemented in the `Buffer` class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, model, device):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        # start with random images in the buffer\n",
    "        self.examples = [torch.rand((1, 1, 32, 32), device=self.device) * 2 - 1 for _ in range(128)]\n",
    "\n",
    "    def sample_new_exmps(self, steps, step_size, noise):\n",
    "        n_new = np.random.binomial(128, 0.05)\n",
    "\n",
    "        # Generate new random images for around 5% of the inputs\n",
    "        new_rand_imgs = torch.rand((n_new, 1, 32, 32),  device=self.device) * 2 - 1\n",
    "\n",
    "        # Sample old images from the buffer for the rest\n",
    "        old_imgs = torch.cat(random.choices(self.examples, k=128 - n_new), dim=0)\n",
    "\n",
    "        inp_imgs = torch.cat([new_rand_imgs, old_imgs], dim=0)\n",
    "\n",
    "        # Run Langevin dynamics\n",
    "        new_imgs = generate_samples(self.model, inp_imgs, steps, step_size, noise)\n",
    "\n",
    "        # Update buffer\n",
    "        self.examples = list(torch.split(new_imgs, 1, dim=0)) + self.examples\n",
    "        self.examples = self.examples[:8192]\n",
    "\n",
    "        return new_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Finally define, the Energy class which will be responsible for tuning the weights of our energy model in order to increase the energy on the generated images and decrease it on the training data images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Metric:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, val):\n",
    "        self.total += val.item()\n",
    "        self.count += 1\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count if self.count > 0 else 0.0\n",
    "\n",
    "    def reset(self):\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "class EBM(nn.Module):\n",
    "    def __init__(self, model, alpha, steps, step_size, noise, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        # define the nn energy model \n",
    "        self.model = model\n",
    "\n",
    "        self.buffer = Buffer(self.model, device=device)\n",
    "\n",
    "        # define the hyperparameters\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        self.step_size = step_size\n",
    "        self.noise = noise\n",
    "\n",
    "        self.loss_metric = Metric()\n",
    "        self.reg_loss_metric = Metric()\n",
    "        self.cdiv_loss_metric = Metric()\n",
    "        self.real_out_metric = Metric()\n",
    "        self.fake_out_metric = Metric()\n",
    "\n",
    "    def metrics(self):\n",
    "        return {\n",
    "            \"loss\": self.loss_metric.result(),\n",
    "            \"reg\": self.reg_loss_metric.result(),\n",
    "            \"cdiv\": self.cdiv_loss_metric.result(),\n",
    "            \"real\": self.real_out_metric.result(),\n",
    "            \"fake\": self.fake_out_metric.result()\n",
    "        }\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for m in [self.loss_metric, self.reg_loss_metric, self.cdiv_loss_metric,\n",
    "                  self.real_out_metric, self.fake_out_metric]:\n",
    "            m.reset()\n",
    "\n",
    "    def train_step(self, real_imgs, optimizer):\n",
    "        real_imgs = real_imgs + torch.randn_like(real_imgs) * self.noise\n",
    "        real_imgs = torch.clamp(real_imgs, -1.0, 1.0)\n",
    "\n",
    "\n",
    "        fake_imgs = self.buffer.sample_new_exmps(\n",
    "            steps=self.steps, step_size=self.step_size, noise=self.noise)\n",
    "\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "        inp_imgs = inp_imgs.clone().detach().to(device).requires_grad_(False)\n",
    "\n",
    "        out_scores = self.model(inp_imgs)\n",
    "\n",
    "        real_out, fake_out = torch.split(out_scores, [real_imgs.size(0), fake_imgs.size(0)], dim=0)\n",
    "\n",
    "        cdiv_loss = real_out.mean() - fake_out.mean() \n",
    "        reg_loss = self.alpha * (real_out.pow(2).mean() + fake_out.pow(2).mean())\n",
    "        loss = cdiv_loss + reg_loss \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        self.loss_metric.update(loss)\n",
    "        self.reg_loss_metric.update(reg_loss)\n",
    "        self.cdiv_loss_metric.update(cdiv_loss)\n",
    "        self.real_out_metric.update(real_out.mean())\n",
    "        self.fake_out_metric.update(fake_out.mean())\n",
    "\n",
    "        return self.metrics()\n",
    "\n",
    "    def test_step(self, real_imgs):\n",
    "        batch_size = real_imgs.shape[0]\n",
    "        fake_imgs = torch.rand((batch_size, 1, 32, 32), device=self.device) * 2 - 1\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_scores = self.model(inp_imgs)\n",
    "            real_out, fake_out = torch.split(out_scores, batch_size, dim=0)\n",
    "            cdiv = real_out.mean() - fake_out.mean()\n",
    "\n",
    "        self.cdiv_loss_metric.update(cdiv)\n",
    "        self.real_out_metric.update(real_out.mean())\n",
    "        self.fake_out_metric.update(fake_out.mean())\n",
    "\n",
    "        return {\n",
    "            \"cdiv\": self.cdiv_loss_metric.result(),\n",
    "            \"real\": self.real_out_metric.result(),\n",
    "            \"fake\": self.fake_out_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def clip_img(x):\n",
    "    return torch.clamp((x + 1) / 2, 0, 1)  # scale from [-1,1] to [0,1]\n",
    "\n",
    "def plot_samples(samples, n=8):\n",
    "    samples = clip_img(samples)\n",
    "    samples = samples.cpu()\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 2, 2))\n",
    "    for i in range(n):\n",
    "        img = samples[i].permute(1, 2, 0).squeeze()  # CHW to HWC\n",
    "        axes[i].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer\n",
    "nn_energy_model = EnergyModel()\n",
    "nn_energy_model.to(device)\n",
    "ebm = EBM(nn_energy_model, alpha=0.1, steps=60, step_size=10, noise=0.005, device=device)\n",
    "optimizer = torch.optim.Adam(nn_energy_model.parameters(), lr=0.0001, betas=(0.0, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    ebm.reset_metrics()\n",
    "    for index, batch in enumerate(train_loader):\n",
    "        real_imgs = batch[0].to(device)\n",
    "        metrics = ebm.train_step(real_imgs, optimizer)\n",
    "\n",
    "    plot_samples(torch.cat(ebm.buffer.examples[-8:]), n=8)\n",
    "    print(f\"Epoch {epoch+1} - \" + \", \".join(f\"{k}: {v:.4f}\" for k, v in metrics.items()))\n",
    "\n",
    "    # Validation step\n",
    "    ebm.reset_metrics()\n",
    "    for batch in test_loader:\n",
    "        real_imgs = batch[0].to(device)\n",
    "        val_metrics = ebm.test_step(real_imgs)\n",
    "\n",
    "    print(f\"Validation - \" + \", \".join(f\"{k}: {v:.4f}\" for k, v in val_metrics.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot 8 grayscale 32x32 images\n",
    "x = torch.rand((8, 1, 32, 32), device=device) * 2 - 1  # Uniform in [-1, 1]\n",
    "new_imgs = generate_samples(nn_energy_model, x, steps=256, step_size=10.0, noise_std=0.01)\n",
    "\n",
    "plot_samples(new_imgs, n=8)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
