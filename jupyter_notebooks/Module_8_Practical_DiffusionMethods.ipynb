{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\u26a0\ufe0f **Static Version Notice**\n",
    "\n",
    "This is a static export of an interactive marimo notebook. Some features have been modified for compatibility:\n",
    "\n",
    "- Interactive UI elements (sliders, dropdowns, text inputs) have been removed\n",
    "- UI variable references have been replaced with default values\n",
    "- Some cells may have been simplified or removed entirely\n",
    "\n",
    "For the full interactive experience, please run the original marimo notebook (.py file) using:\n",
    "```bash\n",
    "uv run marimo edit notebook_name.py\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 8: Practical 2 - Diffusion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Recall that the idea behind Diffusion Models is to map training data to a simple normal distribution by adding noise through a series of steps and then have a neural network **learn** the inverse process.\n",
    "\n",
    "In contrast to autoencoders, the first step is done through simple well defined functions and only the decoder is learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_label = train_dataset[0]\n",
    "print(first_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, label=None):\n",
    "    print(\"Label: \", label)\n",
    "    plt.imshow(image.permute(1,2,0).squeeze(), cmap='gray')\n",
    "    plt.show()\n",
    "show_image(first_image, first_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's take $x_0$ to be a random variable representing images in our data distribution. We will assume that it has mean $0$ and variance $1$. This is ok since we have preprocessed the training images to have mean $0$ and variance $1$.\n",
    "\n",
    "Next, we will corrupt the images by adding standard gaussian noise $\\epsilon$ (mean 0, variance 1). How much noise should be added?\n",
    "\n",
    "To keep the transformed distribution having the same mean and variance, we can control the noise amount using a parameter $\\beta$:\n",
    "\n",
    "$x_1 = \\sqrt{1-\\beta}x_0 + \\sqrt{\\beta} \\epsilon$\n",
    "\n",
    "Then if $x_0$ has mean $0$ and variance $1$, $x_1$ will have mean:\n",
    "\n",
    "$\\sqrt{1-\\beta}*0+\\sqrt{\\beta}*0=0$\n",
    "\n",
    "and variance:\n",
    "\n",
    "$(\\sqrt{1-\\beta})^2*1 + (\\sqrt{\\beta})^2*1=1-\\beta+\\beta=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_image(image, beta = 0.1):\n",
    "    image_with_noise = np.sqrt(1-beta)*image + np.sqrt(beta)*np.random.normal(0, 1, image.shape)\n",
    "    return image_with_noise\n",
    "show_image(corrupt_image(first_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "How does changing $\\beta$ influence the amount of noise added to the image?  Try to find a value that makes the image look like a random noise image.  You can use the slider below to change the value of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(corrupt_image(first_image, beta=slider.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We can repeat this process using the new $x_1$ as the input to the next step, and so on, until we reach $x_T$. Moreover, we can also use a different $\\beta$ for each step. The setup up of how this parameter should vary is referred to as the **diffusion schedule**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We'll want to repeat this process through several iterations, at each step corrupting the image by a small amount. To make things simpler, we can perform some mathematical magic using the fact that multiplying a Gaussian distribution by a constant results in another Gaussian distribution. Similarly, adding two Gaussians results in a Gaussian.  So, one can show mathematically that for two standard Gaussian random variables:\n",
    "\n",
    "$A \\epsilon_0 + B \\epsilon_1 = \\left(\\sqrt{A^2 + B^2}\\right)\\epsilon$, where $\\epsilon$ is also a Gaussian random variable.\n",
    "\n",
    "Hence,\n",
    "\n",
    "$x_2 = \\sqrt{1-\\beta_1}x_1 + \\sqrt{\\beta_1} \\epsilon_1 = \\sqrt{1-\\beta_1}(\\sqrt{1-\\beta_0}x_0 + \\sqrt{\\beta_0} \\epsilon_0) + \\sqrt{\\beta_1} \\epsilon_1 = \\sqrt{(1-\\beta_0)(1-\\beta_1)}x_0 + \\sqrt{\\beta_0(1-\\beta_1)}\\epsilon_0 + \\sqrt{\\beta_1}\\epsilon_1 = \\sqrt{(1-\\beta_0)(1-\\beta_1)}x_0 + \\sqrt{1 - (1-\\beta_0)(1-\\beta_1)}\\epsilon$\n",
    "\n",
    "This will be used later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's look at an example of a diffusion schedule that we'll use in our final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_diffusion_schedule(diffusion_times):\n",
    "    min_rate = 0.0001\n",
    "    max_rate = 0.02\n",
    "    betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    signal_rates = torch.sqrt(alpha_bars)\n",
    "    noise_rates = torch.sqrt(1 - alpha_bars)\n",
    "    return noise_rates, signal_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(train_loader))\n",
    "noises = torch.randn(size=(BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE))\n",
    "diffusion_times = torch.rand(size=(BATCH_SIZE, 1, 1, 1))\n",
    "noise_rates, signal_rates = linear_diffusion_schedule(diffusion_times)\n",
    "noisy_images = signal_rates * images + noise_rates * noises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "grid = make_grid(noisy_images, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, num_frequencies=16):\n",
    "        super().__init__()\n",
    "        self.num_frequencies = num_frequencies\n",
    "        frequencies = torch.exp(torch.linspace(math.log(1.0), math.log(1000.0), num_frequencies))\n",
    "        self.register_buffer(\"angular_speeds\", 2.0 * math.pi * frequencies.view(1, 1, 1, -1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, 1, 1, 1)\n",
    "        returns: Tensor of shape (B, 1, 1, 2 * num_frequencies)\n",
    "        \"\"\"\n",
    "        x = x.expand(-1, 1, 1, self.num_frequencies)\n",
    "        sin_part = torch.sin(self.angular_speeds * x)\n",
    "        cos_part = torch.cos(self.angular_speeds * x)\n",
    "        return torch.cat([sin_part, cos_part], dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Next we build the three new layers used in a UNet neural network, a popular architecture used in Diffusion Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_channels = x.shape[1]\n",
    "        if in_channels != self.width:\n",
    "            skip_conv = nn.Conv2d(in_channels, self.width, kernel_size=1).to(x.device)\n",
    "        else:\n",
    "            skip_conv = nn.Identity()\n",
    "\n",
    "        norm = nn.BatchNorm2d(in_channels, affine=False).to(x.device)\n",
    "        conv1 = nn.Conv2d(in_channels, self.width, kernel_size=3, padding=1).to(x.device)\n",
    "        conv2 = nn.Conv2d(self.width, self.width, kernel_size=3, padding=1).to(x.device)\n",
    "\n",
    "        residual = skip_conv(x)\n",
    "        x = norm(x)\n",
    "        x = F.silu(conv1(x))  # Swish = SiLU\n",
    "        x = conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, width, block_depth):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(width) for _ in range(block_depth)])\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            skips.append(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, width, block_depth):\n",
    "        super().__init__()\n",
    "        self.block_depth = block_depth\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(width * 2 if i == 0 else width) for i in range(block_depth)])\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        for i in range(self.block_depth):\n",
    "            skip = skips.pop()\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.blocks[i](x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, image_size, num_channels, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Conv2d(num_channels, 32, kernel_size=1)\n",
    "        self.num_channels = num_channels\n",
    "        self.image_size = image_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = SinusoidalEmbedding(num_frequencies=16)\n",
    "        self.embedding_proj = nn.Conv2d(embedding_dim, 32, kernel_size=1)\n",
    "\n",
    "        self.down1 = DownBlock(32, block_depth=2)\n",
    "        self.down2 = DownBlock(64, block_depth=2)\n",
    "        self.down3 = DownBlock(96, block_depth=2)\n",
    "\n",
    "        self.mid1 = ResidualBlock(128)\n",
    "        self.mid2 = ResidualBlock(128)\n",
    "\n",
    "        self.up1 = UpBlock(96, block_depth=2)\n",
    "        self.up2 = UpBlock(64, block_depth=2)\n",
    "        self.up3 = UpBlock(32, block_depth=2)\n",
    "\n",
    "        self.final = nn.Conv2d(32, num_channels, kernel_size=1)\n",
    "        nn.init.zeros_(self.final.weight)\n",
    "\n",
    "    def forward(self, noisy_images, noise_variances):\n",
    "        skips = []\n",
    "        x = self.initial(noisy_images)\n",
    "\n",
    "        noise_emb = self.embedding(noise_variances)  # shape: (B, 1, 1, 32)\n",
    "        noise_emb = F.interpolate(noise_emb.permute(0, 3, 1, 2), size=(self.embedding_dim, self.embedding_dim), mode='nearest')\n",
    "        x = torch.cat([x, self.embedding_proj(noise_emb)], dim=1)\n",
    "\n",
    "        x = self.down1(x, skips)\n",
    "        x = self.down2(x, skips)\n",
    "        x = self.down3(x, skips)\n",
    "\n",
    "        x = self.mid1(x)\n",
    "        x = self.mid2(x)\n",
    "\n",
    "        x = self.up1(x, skips)\n",
    "        x = self.up2(x, skips)\n",
    "        x = self.up3(x, skips)\n",
    "\n",
    "        return self.final(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, model, schedule_fn):\n",
    "        super().__init__()\n",
    "        self.network = model\n",
    "        self.ema_network = UNet(model.image_size, model.num_channels, model.embedding_dim)\n",
    "        self.ema_network.load_state_dict(model.state_dict())\n",
    "        self.ema_decay = 0.999\n",
    "        self.schedule_fn = schedule_fn\n",
    "        self.normalizer_mean = 0.0\n",
    "        self.normalizer_std = 1.0\n",
    "\n",
    "    def set_normalizer(self, mean, std):\n",
    "        self.normalizer_mean = mean\n",
    "        self.normalizer_std = std\n",
    "\n",
    "    def denormalize(self, x):\n",
    "        return torch.clamp(x * self.normalizer_std + self.normalizer_mean, 0.0, 1.0)\n",
    "\n",
    "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
    "        network = self.network if training else self.ema_network\n",
    "        pred_noises = network(noisy_images, noise_rates ** 2)\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "        return pred_noises, pred_images\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "        current_images = initial_noise\n",
    "        for step in range(diffusion_steps):\n",
    "            t = torch.ones((initial_noise.shape[0], 1, 1, 1), device=initial_noise.device) * (1 - step * step_size)\n",
    "            noise_rates, signal_rates = self.schedule_fn(t)\n",
    "            pred_noises, pred_images = self.denoise(current_images, noise_rates, signal_rates, training=False)\n",
    "            next_t = t - step_size\n",
    "            next_noise_rates, next_signal_rates = self.schedule_fn(next_t)\n",
    "            current_images = next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
    "        return pred_images\n",
    "\n",
    "    def generate(self, num_images, diffusion_steps, image_size=64, initial_noise=None):\n",
    "        if initial_noise is None:\n",
    "            initial_noise = torch.randn((num_images, 1, image_size, image_size), device=next(self.parameters()).device)\n",
    "        with torch.no_grad():\n",
    "            return self.denormalize(self.reverse_diffusion(initial_noise, diffusion_steps))\n",
    "\n",
    "    def train_step(self, images, optimizer, loss_fn):\n",
    "        images = (images - self.normalizer_mean) / self.normalizer_std\n",
    "        noises = torch.randn_like(images)\n",
    "\n",
    "        diffusion_times = torch.rand((images.size(0), 1, 1, 1), device=images.device)\n",
    "        noise_rates, signal_rates = self.schedule_fn(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        pred_noises, _ = self.denoise(noisy_images, noise_rates, signal_rates, training=True)\n",
    "        loss = loss_fn(pred_noises, noises)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for ema_param, param in zip(self.ema_network.parameters(), self.network.parameters()):\n",
    "                ema_param.copy_(self.ema_decay * ema_param + (1. - self.ema_decay) * param)\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def test_step(self, images, loss_fn):\n",
    "        images = (images - self.normalizer_mean) / self.normalizer_std\n",
    "        noises = torch.randn_like(images)\n",
    "\n",
    "        diffusion_times = torch.rand((images.size(0), 1, 1, 1), device=images.device)\n",
    "        noise_rates, signal_rates = self.schedule_fn(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_noises, _ = self.denoise(noisy_images, noise_rates, signal_rates, training=False)\n",
    "            loss = loss_fn(pred_noises, noises)\n",
    "\n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLJB",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The training loop looks similar to the one used in the previous modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_diffusion(model, train_loader, val_loader, optimizer, loss_fn, epochs=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        loader_with_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for images, _  in loader_with_progress:\n",
    "            images = images.to(device)\n",
    "            loss = model.train_step(images, optimizer, loss_fn)\n",
    "            train_losses.append(loss)\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        for images, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            images = images.to(device)\n",
    "            loss = model.test_step(images, loss_fn)\n",
    "            val_losses.append(loss)\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        loader_with_progress.set_postfix(loss=f'{avg_train_loss:.4f}')\n",
    "        #print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjVT",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images\n",
    "diffusion_model.eval()\n",
    "samples = diffusion_model.generate(num_images=1, image_size=IMAGE_SIZE, diffusion_steps=1000)  # returns tensor in [0, 1]\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "image = samples[0].cpu()\n",
    "\n",
    "# Plot\n",
    "show_image(image)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}