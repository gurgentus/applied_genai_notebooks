{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e6ca7a",
   "metadata": {},
   "source": [
    "⚠️ **Static Version Notice**\n",
    "\n",
    "This is a static export of an interactive marimo notebook. Some features have been modified for compatibility:\n",
    "\n",
    "- Interactive UI elements (sliders, dropdowns, text inputs) have been removed\n",
    "- UI variable references have been replaced with default values\n",
    "- Some cells may have been simplified or removed entirely\n",
    "\n",
    "For the full interactive experience, please run the original marimo notebook (.py file) using:\n",
    "```bash\n",
    "uv run marimo edit notebook_name.py\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"bash\", \"-c\", \"uv run python -m spacy download en_core_web_lg\"],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we import the *spacy* library and load the large English model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Next, let's define a function to calculate word embeddings based on an input word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(input_word):\n",
    "    word = nlp(input_word)\n",
    "    return word.vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's try with the word 'apple'.  For brevity, only the first elements of the embedding vector are displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_embedding(\"apple\")[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "word_embedding = calculate_embedding(\"example_text\")\n",
    "word_embedding[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Similarity\n",
    "Let's add a function to calculate the similarity between two words based on their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(word1, word2):\n",
    "    return nlp(word1).similarity(nlp(word2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Compare embeddings of words: 'apple' and 'car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_similarity(\"apple\", \"car\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "calculate_similarity(\"example_text\", \"example_text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "la_word1_embedding = nlp(\"example_text\").vector\n",
    "la_word2_embedding = nlp(\"example_text\").vector\n",
    "la_word3_embedding = nlp(\"example_text\").vector\n",
    "la_word = la_word1_embedding + (la_word2_embedding - la_word3_embedding)\n",
    "la_word4 = nlp(\"example_text\").vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Cosine similarity: \", cosine_similarity([la_word], [la_word4])[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "----\n",
    "## Sentence Embeddings\n",
    "\n",
    "Finally, to calculate an embedding for a sentence, we can just average the embeddings of all the words in that sentence.  We will again use `spacy` to calculate the sentence embeddings.\n",
    "\n",
    "```python\n",
    "query = \"What is the capital of France?\"\n",
    "info_1 = \"The capital of France is Paris\"\n",
    "info_2 = \"France is a beautiful country\"\n",
    "info_3 = \"Today is very warm in New York City\"\n",
    "print(\"Response 1 Similarity: \", nlp(query).similarity(nlp(info_1)))\n",
    "print(\"Response 2 Similarity: \", nlp(query).similarity(nlp(info_2)))\n",
    "print(\"Response 3 Similarity: \", nlp(query).similarity(nlp(info_3)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "info_1 = \"The capital of France is Paris\"\n",
    "info_2 = \"France is a beautiful country\"\n",
    "info_3 = \"Today is very warm in New York City\"\n",
    "print(\"Response 1 Similarity: \", nlp(query).similarity(nlp(info_1)))\n",
    "print(\"Response 2 Similarity: \", nlp(query).similarity(nlp(info_2)))\n",
    "print(\"Response 3 Similarity: \", nlp(query).similarity(nlp(info_3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Being able to quickly calculate similarities between a query and target information text is very powerful for Information Retrieval, especially when combined with Large Language Models trained for chat/question answering capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
